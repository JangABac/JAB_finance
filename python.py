# python.py

import streamlit as st
import pandas as pd
from google import genai
from google.genai.errors import APIError

# --- Cáº¥u hÃ¬nh Trang Streamlit ---
st.set_page_config(
    page_title="App PhÃ¢n TÃ­ch BÃ¡o CÃ¡o TÃ i ChÃ­nh",
    layout="wide"
)

# TiÃªu Ä‘á» in Ä‘áº­m, mÃ u Ä‘á», cuá»‘i cÃ³ biá»ƒu tÆ°á»£ng $
st.markdown("<h1 style='color:red; font-weight:bold;'>á»¨ng dá»¥ng PhÃ¢n TÃ­ch BÃ¡o CÃ¡o TÃ i ChÃ­nh $</h1>", unsafe_allow_html=True)

# --- HÃ m tÃ­nh toÃ¡n chÃ­nh (Sá»­ dá»¥ng Caching Ä‘á»ƒ Tá»‘i Æ°u hiá»‡u suáº¥t) ---
@st.cache_data
def process_financial_data(df):
    """Thá»±c hiá»‡n cÃ¡c phÃ©p tÃ­nh TÄƒng trÆ°á»Ÿng vÃ  Tá»· trá»ng."""
    
    # Äáº£m báº£o cÃ¡c giÃ¡ trá»‹ lÃ  sá»‘ Ä‘á»ƒ tÃ­nh toÃ¡n
    numeric_cols = ['NÄƒm trÆ°á»›c', 'NÄƒm sau']
    for col in numeric_cols:
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
    
    # 1. TÃ­nh Tá»‘c Ä‘á»™ TÄƒng trÆ°á»Ÿng
    df['Tá»‘c Ä‘á»™ tÄƒng trÆ°á»Ÿng (%)'] = (
        (df['NÄƒm sau'] - df['NÄƒm trÆ°á»›c']) / df['NÄƒm trÆ°á»›c'].replace(0, 1e-9)
    ) * 100

    # 2. TÃ­nh Tá»· trá»ng theo Tá»•ng TÃ i sáº£n
    tong_tai_san_row = df[df['Chá»‰ tiÃªu'].str.contains('Tá»”NG Cá»˜NG TÃ€I Sáº¢N', case=False, na=False)]
    
    if tong_tai_san_row.empty:
        raise ValueError("KhÃ´ng tÃ¬m tháº¥y chá»‰ tiÃªu 'Tá»”NG Cá»˜NG TÃ€I Sáº¢N'.")

    tong_tai_san_N_1 = tong_tai_san_row['NÄƒm trÆ°á»›c'].iloc[0]
    tong_tai_san_N = tong_tai_san_row['NÄƒm sau'].iloc[0]

    divisor_N_1 = tong_tai_san_N_1 if tong_tai_san_N_1 != 0 else 1e-9
    divisor_N = tong_tai_san_N if tong_tai_san_N != 0 else 1e-9

    df['Tá»· trá»ng NÄƒm trÆ°á»›c (%)'] = (df['NÄƒm trÆ°á»›c'] / divisor_N_1) * 100
    df['Tá»· trá»ng NÄƒm sau (%)'] = (df['NÄƒm sau'] / divisor_N) * 100
    
    return df

# --- HÃ m gá»i API Gemini (phÃ¢n tÃ­ch tÃ i chÃ­nh) ---
def get_ai_analysis(data_for_ai, api_key):
    """Gá»­i dá»¯ liá»‡u phÃ¢n tÃ­ch Ä‘áº¿n Gemini API vÃ  nháº­n nháº­n xÃ©t."""
    try:
        client = genai.Client(api_key=api_key)
        model_name = 'gemini-2.5-flash' 

        prompt = f"""
        Báº¡n lÃ  má»™t chuyÃªn gia phÃ¢n tÃ­ch tÃ i chÃ­nh chuyÃªn nghiá»‡p. Dá»±a trÃªn cÃ¡c chá»‰ sá»‘ tÃ i chÃ­nh sau, hÃ£y Ä‘Æ°a ra má»™t nháº­n xÃ©t khÃ¡ch quan, ngáº¯n gá»n (khoáº£ng 3-4 Ä‘oáº¡n) vá» tÃ¬nh hÃ¬nh tÃ i chÃ­nh cá»§a doanh nghiá»‡p. ÄÃ¡nh giÃ¡ táº­p trung vÃ o tá»‘c Ä‘á»™ tÄƒng trÆ°á»Ÿng, thay Ä‘á»•i cÆ¡ cáº¥u tÃ i sáº£n vÃ  kháº£ nÄƒng thanh toÃ¡n hiá»‡n hÃ nh.
        
        Dá»¯ liá»‡u thÃ´ vÃ  chá»‰ sá»‘:
        {data_for_ai}
        """

        response = client.models.generate_content(
            model=model_name,
            contents=prompt
        )
        return response.text

    except APIError as e:
        return f"Lá»—i gá»i Gemini API: {e}"
    except KeyError:
        return "Lá»—i: KhÃ´ng tÃ¬m tháº¥y KhÃ³a API 'GEMINI_API_KEY'."
    except Exception as e:
        return f"ÄÃ£ xáº£y ra lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh: {e}"


# --- Chá»©c nÄƒng 1: Táº£i File ---
uploaded_file = st.file_uploader(
    "1. Táº£i file Excel BÃ¡o cÃ¡o TÃ i chÃ­nh (Chá»‰ tiÃªu | NÄƒm trÆ°á»›c | NÄƒm sau)",
    type=['xlsx', 'xls']
)

if uploaded_file is not None:
    try:
        df_raw = pd.read_excel(uploaded_file)
        df_raw.columns = ['Chá»‰ tiÃªu', 'NÄƒm trÆ°á»›c', 'NÄƒm sau']
        
        df_processed = process_financial_data(df_raw.copy())

        if df_processed is not None:
            st.subheader("2. Tá»‘c Ä‘á»™ TÄƒng trÆ°á»Ÿng & 3. Tá»· trá»ng CÆ¡ cáº¥u TÃ i sáº£n")
            st.dataframe(df_processed.style.format({
                'NÄƒm trÆ°á»›c': '{:,.0f}',
                'NÄƒm sau': '{:,.0f}',
                'Tá»‘c Ä‘á»™ tÄƒng trÆ°á»Ÿng (%)': '{:.2f}%',
                'Tá»· trá»ng NÄƒm trÆ°á»›c (%)': '{:.2f}%',
                'Tá»· trá»ng NÄƒm sau (%)': '{:.2f}%'
            }), use_container_width=True)
            
            st.subheader("4. CÃ¡c Chá»‰ sá»‘ TÃ i chÃ­nh CÆ¡ báº£n")
            try:
                tsnh_n = df_processed[df_processed['Chá»‰ tiÃªu'].str.contains('TÃ€I Sáº¢N NGáº®N Háº N', case=False, na=False)]['NÄƒm sau'].iloc[0]
                tsnh_n_1 = df_processed[df_processed['Chá»‰ tiÃªu'].str.contains('TÃ€I Sáº¢N NGáº®N Háº N', case=False, na=False)]['NÄƒm trÆ°á»›c'].iloc[0]
                no_ngan_han_N = df_processed[df_processed['Chá»‰ tiÃªu'].str.contains('Ná»¢ NGáº®N Háº N', case=False, na=False)]['NÄƒm sau'].iloc[0]  
                no_ngan_han_N_1 = df_processed[df_processed['Chá»‰ tiÃªu'].str.contains('Ná»¢ NGáº®N Háº N', case=False, na=False)]['NÄƒm trÆ°á»›c'].iloc[0]

                thanh_toan_hien_hanh_N = tsnh_n / no_ngan_han_N
                thanh_toan_hien_hanh_N_1 = tsnh_n_1 / no_ngan_han_N_1
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Chá»‰ sá»‘ Thanh toÃ¡n Hiá»‡n hÃ nh (NÄƒm trÆ°á»›c)", f"{thanh_toan_hien_hanh_N_1:.2f} láº§n")
                with col2:
                    st.metric("Chá»‰ sá»‘ Thanh toÃ¡n Hiá»‡n hÃ nh (NÄƒm sau)", f"{thanh_toan_hien_hanh_N:.2f} láº§n",
                              delta=f"{thanh_toan_hien_hanh_N - thanh_toan_hien_hanh_N_1:.2f}")
            except IndexError:
                st.warning("Thiáº¿u chá»‰ tiÃªu 'TÃ€I Sáº¢N NGáº®N Háº N' hoáº·c 'Ná»¢ NGáº®N Háº N'.")

            st.subheader("5. Nháº­n xÃ©t TÃ¬nh hÃ¬nh TÃ i chÃ­nh (AI)")
            data_for_ai = pd.DataFrame({
                'Chá»‰ tiÃªu': [
                    'ToÃ n bá»™ Báº£ng phÃ¢n tÃ­ch (dá»¯ liá»‡u thÃ´)', 
                    'TÄƒng trÆ°á»Ÿng TÃ i sáº£n ngáº¯n háº¡n (%)', 
                    'Thanh toÃ¡n hiá»‡n hÃ nh (N-1)', 
                    'Thanh toÃ¡n hiá»‡n hÃ nh (N)'
                ],
                'GiÃ¡ trá»‹': [
                    df_processed.to_markdown(index=False),
                    f"{df_processed[df_processed['Chá»‰ tiÃªu'].str.contains('TÃ€I Sáº¢N NGáº®N Háº N', case=False, na=False)]['Tá»‘c Ä‘á»™ tÄƒng trÆ°á»Ÿng (%)'].iloc[0]:.2f}%", 
                    "N/A", 
                    "N/A"
                ]
            }).to_markdown(index=False) 

            if st.button("YÃªu cáº§u AI PhÃ¢n tÃ­ch"):
                api_key = st.secrets.get("GEMINI_API_KEY") 
                if api_key:
                    with st.spinner('Äang gá»­i dá»¯ liá»‡u vÃ  chá» Gemini phÃ¢n tÃ­ch...'):
                        ai_result = get_ai_analysis(data_for_ai, api_key)
                        st.markdown("**Káº¿t quáº£ PhÃ¢n tÃ­ch tá»« Gemini AI:**")
                        st.info(ai_result)
                else:
                    st.error("Lá»—i: KhÃ´ng tÃ¬m tháº¥y KhÃ³a API.")
    except ValueError as ve:
        st.error(f"Lá»—i cáº¥u trÃºc dá»¯ liá»‡u: {ve}")
    except Exception as e:
        st.error(f"CÃ³ lá»—i xáº£y ra khi Ä‘á»c file: {e}")
else:
    st.info("Vui lÃ²ng táº£i lÃªn file Excel Ä‘á»ƒ báº¯t Ä‘áº§u phÃ¢n tÃ­ch.")

# ======================================================================
# ğŸ’¬ KHUNG CHAT Vá»šI GEMINI
# ======================================================================

st.markdown("---")
st.subheader("ğŸ’¬ Khung Chat vá»›i Gemini")

with st.expander("âš™ï¸ Cáº¥u hÃ¬nh Chat (tuá»³ chá»n)", expanded=False):
    model = st.selectbox("Chá»n model",
                         ["gemini-2.5-flash", "gemini-2.0-flash", "gemini-1.5-flash", "gemini-2.5-pro"],
                         index=0)
    system_prompt = st.text_area("System prompt",
        value="Báº¡n lÃ  trá»£ lÃ½ Python & tÃ i chÃ­nh. Tráº£ lá»i ngáº¯n gá»n, cÃ³ vÃ­ dá»¥ khi cáº§n.", height=100)
    max_history = st.slider("Sá»‘ lÆ°á»£t há»™i thoáº¡i Ä‘Æ°a vÃ o ngá»¯ cáº£nh", 2, 20, 12)

if "chat_messages" not in st.session_state:
    st.session_state.chat_messages = []

for msg in st.session_state.chat_messages:
    with st.chat_message("user" if msg["role"] == "user" else "assistant"):
        st.markdown(msg["content"])

def _format_history_for_prompt(history, system_prompt, last_user):
    lines = [f"[SYSTEM]\n{system_prompt.strip()}", ""]
    for turn in history[-max_history:]:
        if turn["role"] == "user":
            lines.append(f"[USER]\n{turn['content']}\n")
        else:
            lines.append(f"[ASSISTANT]\n{turn['content']}\n")
    lines.append(f"[USER]\n{last_user}\n")
    lines.append("[ASSISTANT]\n")
    return "\n".join(lines).strip()

def _call_gemini_chat(api_key, model_name, system_prompt, history, user_text):
    try:
        client = genai.Client(api_key=api_key)
        prompt_text = _format_history_for_prompt(history, system_prompt, user_text)
        resp = client.models.generate_content(model=model_name, contents=prompt_text)
        return (resp.text or "").strip()
    except Exception as e:
        return f"âš ï¸ Lá»—i gá»i Gemini: {e}"

user_input = st.chat_input("Nháº­p cÃ¢u há»i cho Gemini...")

if user_input:
    st.session_state.chat_messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    api_key = st.secrets.get("GEMINI_API_KEY")
    if not api_key:
        assistant_reply = "âš ï¸ ChÆ°a cáº¥u hÃ¬nh `GEMINI_API_KEY`."
        with st.chat_message("assistant"):
            st.markdown(assistant_reply)
        st.session_state.chat_messages.append({"role": "assistant", "content": assistant_reply})
    else:
        with st.chat_message("assistant"):
            with st.spinner("Gemini Ä‘ang soáº¡n tráº£ lá»i..."):
                assistant_reply = _call_gemini_chat(api_key, model, system_prompt,
                                                    st.session_state.chat_messages[:-1], user_input)
                st.markdown(assistant_reply)
        st.session_state.chat_messages.append({"role": "assistant", "content": assistant_reply})
